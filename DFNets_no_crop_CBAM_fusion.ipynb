{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f6a4c1e",
   "metadata": {},
   "source": [
    "# DFNets with CBAM Fusion for Face Anti-Spoofing\n",
    "\n",
    "This notebook implements a deep learning model for face anti-spoofing using DFNets architecture with CBAM (Convolutional Block Attention Module) fusion mechanism on the OULU-NPU dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import random\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423295cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "# os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1'  # penting untuk determinisme op tf\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd519399",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoFramesDataset:\n",
    "    def __init__(self, root_dir, annotation_file, n_frames=10, transform=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.n_frames = n_frames\n",
    "        #self._parse_annotationfile()\n",
    "\n",
    "        self.video_list = annotation_file[0]\n",
    "        self.label = annotation_file[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_list)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def  __call__(self):\n",
    "        for idx in range(len(self.video_list)):\n",
    "            frame = np.load(os.path.join(self.root_dir, self.video_list[idx][3:]+\".npy\"))\n",
    "            #frame = frames_from_video_file(os.path.join(self.root_dir, self.video_list[idx][3:]+\".avi\"), 20, output_size = (224,224), frame_step = 15)\n",
    "            \n",
    "            # Sample n_frames frames from the available frames\n",
    "            total_frames = frame.shape[0]\n",
    "            if total_frames >= self.n_frames:\n",
    "                # Sample n_frames frames evenly distributed across the video\n",
    "                indices = np.linspace(0, total_frames-1, self.n_frames, dtype=int)\n",
    "                frame = frame[indices]  # Shape: (n_frames, 224, 224, 3)\n",
    "            else:\n",
    "                # If less than n_frames frames, repeat the last frame\n",
    "                needed_frames = self.n_frames - total_frames\n",
    "                last_frame = frame[-1:].repeat(needed_frames, axis=0)\n",
    "                frame = np.concatenate([frame, last_frame], axis=0)\n",
    "            \n",
    "            #print(frame.dtype)\n",
    "            if self.label[idx][0] == \"+\":\n",
    "                label = tf.convert_to_tensor([0])\n",
    "            else:\n",
    "                label = tf.convert_to_tensor([1])\n",
    "            #label = tf.convert_to_tensor(int(self.label[idx][-1])-1)\n",
    "            yield tf.convert_to_tensor(frame, dtype=tf.float32), (label, label, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754025831.089726    1453 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5660 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050, pci bus id: 0000:10:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "n_frames = 10\n",
    "batch_size = 2\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "#path = \"G:/My Drive/Pindahan\"\n",
    "path = \".\"\n",
    "\n",
    "# def augmentation(frame):\n",
    "#   # contrast\n",
    "#   # brightness\n",
    "#   #gamma = np.random.uniform(low=0.5,high=0.8,size=[1,])\n",
    "#   #frame = tf.image.adjust_gamma(frame, gamma[0], 1)\n",
    "#   frame = tf.image.random_contrast(frame,0,2)\n",
    "#   frame = tf.image.random_flip_left_right(frame)\n",
    "#   frame = tf.image.random_brightness(frame,0.1)\n",
    "#   #frame = tf.image.resize(frame,(448,tf.random.uniform([1],180,200,dtype=tf.int32)[0]))\n",
    "#   #frame = tf.image.resize_with_crop_or_pad(frame,224,224)\n",
    "#   return frame\n",
    "\n",
    "def augmentation(color_image):\n",
    "    color_image = tf.image.random_brightness(color_image, max_delta=0.1, seed=SEED)\n",
    "    color_image = tf.image.random_contrast(color_image, 0, 2, seed=SEED)\n",
    "    # color_image = tf.image.random_saturation(color_image, lower=0.8, upper=1.2, seed=SEED)\n",
    "    # color_image = tf.image.random_hue(color_image, max_delta=0.2, seed=SEED)\n",
    "    color_image = tf.image.random_flip_left_right(color_image, seed=SEED)\n",
    "    # rot_k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32, seed=42)\n",
    "\n",
    "    # def rotate(frame):\n",
    "    #     frame = tf.image.rot90(frame, k=rot_k)\n",
    "    #     return frame\n",
    "\n",
    "    # color_image = tf.map_fn(rotate, color_image)\n",
    "    color_image = tf.clip_by_value(color_image, 0.0, 1.0)\n",
    "    return color_image\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomContrast(0.4, seed=SEED),\n",
    "    tf.keras.layers.RandomBrightness(0.2, value_range=(0, 1), seed=SEED),\n",
    "    tf.keras.layers.RandomRotation(0.111, seed=SEED),\n",
    "    tf.keras.layers.RandomTranslation(0.2, 0.2, seed=SEED),\n",
    "    tf.keras.layers.RandomZoom(0.2, seed=SEED),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\", seed=SEED),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ccbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = path+\"/OULU-NPU/Train_files/Train_files/output/\"\n",
    "dev_dir = path+\"/OULU-NPU/Dev_files/Dev_files/output/\"\n",
    "test_dir = path+\"/OULU-NPU/Test_files/Test_files/output/\"\n",
    "\n",
    "#train_dir = path+\"/Limited Source/O to I and M/Train OULU/Step 4/\"\n",
    "#train_annotation = pd.read_csv(os.path.join(path,\"OULU-NPU/Train_files/Train_files/output\", \"annotation.txt\"), sep = ' ', header=None).sample(frac=0.5, replace=None, weights=None, random_state=42, axis=None, ignore_index=True)\n",
    "\n",
    "train_annotation = pd.read_csv(os.path.join(path, \"OULU-NPU/Protocols/Protocols/Protocol_1/Train.txt\"), sep = ' ', header=None)\n",
    "dev_annotation = pd.read_csv(os.path.join(path, \"OULU-NPU/Protocols/Protocols/Protocol_1/Dev.txt\"), sep = ' ', header=None)\n",
    "test_annotation = pd.read_csv(os.path.join(path, \"OULU-NPU/Protocols/Protocols/Protocol_1/Test.txt\"), sep = ' ', header=None)\n",
    "#.sample(frac=0.5, replace=False, weights=None, axis=None, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c2923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample filename: +1,1_1_01_1\n",
      "Original shape: (151, 224, 224, 3)\n",
      "Data type: uint8\n",
      "\n",
      "Testing transpose operations:\n",
      "axes=[0,1,2,3] -> (151, 224, 224, 3)\n",
      "axes=[1,2,3,0] -> (224, 224, 3, 151)\n",
      "axes=[3,0,1,2] -> (3, 151, 224, 224)\n",
      "axes=[3,1,2,0] -> (3, 224, 224, 151)\n"
     ]
    }
   ],
   "source": [
    "# Debug: Check the actual shape of loaded data\n",
    "import os\n",
    "sample_file = train_annotation.iloc[0, 0]  # Get first video filename\n",
    "print(f\"Sample filename: {sample_file}\")\n",
    "\n",
    "# Load and check shape\n",
    "sample_data = np.load(os.path.join(train_dir, sample_file[3:] + \".npy\"))\n",
    "print(f\"Original shape: {sample_data.shape}\")\n",
    "print(f\"Data type: {sample_data.dtype}\")\n",
    "\n",
    "# Try different transpose operations\n",
    "print(\"\\nTesting transpose operations:\")\n",
    "print(f\"axes=[0,1,2,3] -> {np.transpose(sample_data, axes=[0,1,2,3]).shape}\")\n",
    "print(f\"axes=[1,2,3,0] -> {np.transpose(sample_data, axes=[1,2,3,0]).shape}\")\n",
    "print(f\"axes=[3,0,1,2] -> {np.transpose(sample_data, axes=[3,0,1,2]).shape}\")\n",
    "print(f\"axes=[3,1,2,0] -> {np.transpose(sample_data, axes=[3,1,2,0]).shape}\")\n",
    "\n",
    "# We need shape (n_frames, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912ca9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated shape: (10, 224, 224, 3)\n",
      "Expected shape: (10, 224, 224, 3)\n",
      "Label shape: (1,)\n",
      "Shape matches expectation: True\n"
     ]
    }
   ],
   "source": [
    "# Test the VideoFramesDataset generator\n",
    "test_dataset = VideoFramesDataset(train_dir, train_annotation, n_frames)\n",
    "test_gen = test_dataset()\n",
    "\n",
    "# Get first sample\n",
    "sample_x, sample_y = next(test_gen)\n",
    "print(f\"Generated shape: {sample_x.shape}\")\n",
    "print(f\"Expected shape: ({n_frames}, 224, 224, 3)\")\n",
    "print(f\"Label shape: {sample_y[0].shape}\")\n",
    "\n",
    "# Verify it matches our output signature\n",
    "print(f\"Shape matches expectation: {sample_x.shape == (n_frames, 224, 224, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_signature = (\n",
    "    tf.TensorSpec(shape=(n_frames, 224, 224, 3), dtype=tf.float32),  # input video frames\n",
    "    (\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.int32),  # for output\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.int32),  # for gap\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.int32),  # for gap_saliency\n",
    "    )\n",
    ")\n",
    "\n",
    "train_ds_oulu = tf.data.Dataset.from_generator(VideoFramesDataset(train_dir, train_annotation, n_frames), output_signature = output_signature)\n",
    "train_ds_oulu = train_ds_oulu.shuffle(32, seed=SEED, reshuffle_each_iteration=True)\n",
    "train_ds_oulu = train_ds_oulu.map(lambda x, y: (augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds_oulu = train_ds_oulu.batch(batch_size).prefetch(tf.data.AUTOTUNE).cache().repeat()\n",
    "\n",
    "dev_ds_oulu = tf.data.Dataset.from_generator(VideoFramesDataset(dev_dir, dev_annotation, n_frames), output_signature = output_signature)\n",
    "dev_ds_oulu = dev_ds_oulu.shuffle(32).batch(batch_size).prefetch(AUTOTUNE)\n",
    "\n",
    "test_ds_oulu = tf.data.Dataset.from_generator(VideoFramesDataset(test_dir, test_annotation, n_frames), output_signature = output_signature)\n",
    "test_ds_oulu = test_ds_oulu.batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== NON-OULU DATASET CODE (COMMENTED OUT) =====================\n",
    "# class VideoFramesDatasetMSU:\n",
    "#     def __init__(self, root_dir, annotation_file, transform=False):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform\n",
    "#         #self._parse_annotationfile()\n",
    "#\n",
    "#         self.video_list = annotation_file[0]\n",
    "#         self.label = annotation_file[1]\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.video_list)\n",
    "#\n",
    "#     def on_epoch_end(self):\n",
    "#         pass\n",
    "#\n",
    "#     def  __call__(self):\n",
    "#         for idx in range(len(self.video_list)):\n",
    "#             frame = np.load(os.path.join(self.root_dir, self.video_list[idx]))\n",
    "#             #frame = (frame-frame.mean())/frame.std()\n",
    "#             frame = np.transpose(frame, axes=[0, 2, 3, 1])\n",
    "#             if self.label[idx] == 0:\n",
    "#                 label = tf.convert_to_tensor(0)\n",
    "#             else:\n",
    "#                 label = tf.convert_to_tensor(1)\n",
    "#\n",
    "#             label = tf.convert_to_tensor([label])\n",
    "#\n",
    "#             yield tf.convert_to_tensor(frame), label\n",
    "#\n",
    "# test_dir_msu = path+\"/MSU-MFSD/MSU-MFSD-Publish.zip/scene01/output/\"\n",
    "# #test_dir_msu = \"./Limited Source/O to I and M/Test MSU-MFSD/Step 2/\"\n",
    "#\n",
    "# test_annotation_msu = pd.read_csv(path+\"/MSU-MFSD/MSU-MFSD-Publish.zip/scene01/output/annotation.txt\", sep = ',', header=None)\n",
    "# selection = pd.read_csv(path+\"/MSU-MFSD/MSU-MFSD-Publish.zip/test_sub_list.txt\", header=None).values[:,0].astype(\"str\").tolist()\n",
    "# selection = ['0' + s if len(s)>1 else '00'+s for s in selection]\n",
    "# test_annotation_msu = test_annotation_msu[test_annotation_msu.iloc[:,[0]].squeeze().str.contains('|'.join(selection))].reset_index().iloc[:,1:]\n",
    "#\n",
    "# output_signature = (\n",
    "#     tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),  # video frame sequence\n",
    "#     tf.TensorSpec(shape=(1,), dtype=tf.int32)                    # batch of 1 label\n",
    "#     )\n",
    "#\n",
    "# val_ds_msu = tf.data.Dataset.from_generator(VideoFramesDatasetMSU(test_dir_msu, test_annotation_msu), output_signature = output_signature)\n",
    "# val_ds_msu = val_ds_msu.batch(batch_size).prefetch(AUTOTUNE)\n",
    "#\n",
    "# class VideoFramesDatasetIdiap:\n",
    "#     def __init__(self, root_dir, annotation_file):\n",
    "#         self.root_dir = root_dir\n",
    "#         #self._parse_annotationfile()\n",
    "#\n",
    "#         self.video_list = annotation_file[0]\n",
    "#         self.label = annotation_file[1]\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.video_list)\n",
    "#\n",
    "#     def on_epoch_end(self):\n",
    "#         pass\n",
    "#\n",
    "#     def  __call__(self):\n",
    "#         for idx in range(len(self.video_list)):\n",
    "#             frame = np.load(os.path.join(self.root_dir, self.video_list[idx]))\n",
    "#             frame = np.transpose(frame, axes=[0, 2, 3, 1])\n",
    "#             # frame = exposure.adjust_gamma(frame, 0.5)\n",
    "#             if self.label[idx] == 0:\n",
    "#                 label = tf.convert_to_tensor(0)\n",
    "#             else:\n",
    "#                 label = tf.convert_to_tensor(1)\n",
    "#\n",
    "#             label = tf.convert_to_tensor([label])\n",
    "#\n",
    "#             yield tf.convert_to_tensor(frame), label\n",
    "#\n",
    "# test_dir_idiap = path+\"/Idiap/replayattack-test.tar.gz/test/output/\"\n",
    "# #test_dir_idiap = path+\"/Limited Source/O to I and M/Test Idiap/Step 4/\"\n",
    "# test_annotation_idiap = pd.read_csv(path+\"/Idiap/replayattack-test.tar.gz/test/output/annotation.txt\", sep = ',', header=None)\n",
    "#\n",
    "# train_dir_idiap = path+\"/Idiap/replayattack-train.tar.gz/train/output/\"\n",
    "# train_annotation_idiap = pd.read_csv(train_dir_idiap+\"/annotation.txt\", sep = ',', header=None)\n",
    "#\n",
    "# train_ds_idiap = tf.data.Dataset.from_generator(VideoFramesDatasetIdiap(train_dir_idiap, train_annotation_idiap), output_signature = output_signature)\n",
    "# train_ds_idiap = train_ds_idiap.batch(batch_size)\n",
    "# train_ds_idiap = train_ds_idiap.prefetch(AUTOTUNE)\n",
    "#\n",
    "# val_ds_idiap = tf.data.Dataset.from_generator(VideoFramesDatasetIdiap(test_dir_idiap, test_annotation_idiap), output_signature = output_signature)\n",
    "# val_ds_idiap = val_ds_idiap.batch(batch_size).prefetch(AUTOTUNE)\n",
    "# ===================== END NON-OULU DATASET CODE ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d825b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttentionModule(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape: (B, H, W, C)\n",
    "        # output: same spatial dims, last channel = 1\n",
    "        return input_shape[:-1] + (1,)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_out = tf.reduce_mean(inputs, axis=-1, keepdims=True)\n",
    "        max_out = tf.reduce_max(inputs, axis=-1, keepdims=True)\n",
    "        concat = tf.concat([avg_out, max_out], axis=-1)\n",
    "        return self.conv(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41adc624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"# Create Model\"\"\n",
    "def build_dfnet_model(video_input, base_filters=32):\n",
    "\n",
    "    # Shared feature extractor for each frame\n",
    "    base_cnn = tf.keras.applications.ResNet50(\n",
    "        include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\"\n",
    "    )\n",
    "    base_cnn.trainable = True\n",
    "\n",
    "    # Choose a mid-layer to cut at\n",
    "    #truncated_base = Model(inputs=base_cnn.input, outputs=base_cnn.get_layer(\"block_5_add\").output)\n",
    "\n",
    "    base_cnn_saliency = tf.keras.applications.EfficientNetB0(\n",
    "        include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\"\n",
    "    )\n",
    "    base_cnn_saliency.trainable = True\n",
    "\n",
    "    #truncated_saliency = Model(inputs=base_cnn_saliency.input, outputs=base_cnn_saliency.get_layer(\"block3a_activation\").output)\n",
    "\n",
    "    feature_extractor = tf.keras.Sequential([\n",
    "        # layers.Rescaling(scale=255),\n",
    "        base_cnn\n",
    "        # truncated_base\n",
    "    ])\n",
    "\n",
    "    feature_extractor_saliency = tf.keras.Sequential([\n",
    "        # layers.Rescaling(scale=255),\n",
    "        base_cnn_saliency\n",
    "        # truncated_saliency\n",
    "    ])\n",
    "\n",
    "    # Process each frame\n",
    "    features = layers.TimeDistributed(feature_extractor)(video_input)  # (B, N, 7, 7, F)\n",
    "    # features = layers.TimeDistributed(layers.UpSampling2D(size=(2, 2)))(features)\n",
    "\n",
    "    # Generate occlusion mask\n",
    "    # masks = cefe_attention_module(features_0)\n",
    "    # masks = layers.TimeDistributed(saliency_branch)(features_0)  # (B, N, H, W, 3)\n",
    "    # saliency_masks = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(features)  # (B, N, 7, 7, 1)\n",
    "\n",
    "    saliency_masks = layers.TimeDistributed(SpatialAttentionModule())(features)\n",
    "\n",
    "    # Resize masks to (224, 224)\n",
    "    saliency_masks = layers.TimeDistributed(\n",
    "        layers.Resizing(224, 224, interpolation='bilinear')\n",
    "    )(saliency_masks)  # (B, N, 224, 224, 1)\n",
    "\n",
    "    # Normalize to [0, 1]\n",
    "    saliency_masks = layers.Lambda(lambda x: (x - tf.reduce_min(x)) / (tf.reduce_max(x) - tf.reduce_min(x) + 1e-6))(saliency_masks)\n",
    "\n",
    "    # masks = layers.UpSampling3D((1,32,32))(masks)\n",
    "    #saliency_masks = layers.Lambda(lambda x: 1.0 - x)(saliency_masks)  # invert --> masks = 1-masks\n",
    "\n",
    "    epsilon = 0.1  # Avoid fully black regions\n",
    "    soft_mask = layers.Lambda(lambda x: tf.clip_by_value(1.0 - x, epsilon, 1.0))(saliency_masks)\n",
    "\n",
    "    # Apply occlusion\n",
    "    masked_input = layers.Multiply()([video_input, soft_mask])\n",
    "\n",
    "    features_saliency = layers.TimeDistributed(feature_extractor_saliency)(masked_input)  # (B, N, 7, 7, F)\n",
    "\n",
    "    drop = layers.Dropout(0.3)(features)\n",
    "    dense = layers.Dense(1, name=\"dense\")(drop)\n",
    "    gap = layers.GlobalAveragePooling3D(name=\"out\")(dense)\n",
    "\n",
    "    drop_saliency = layers.Dropout(0.3)(features_saliency)\n",
    "    dense_saliency = layers.Dense(1, name=\"dense_saliency\")(drop_saliency)\n",
    "    gap_saliency = layers.GlobalAveragePooling3D(name='out_sal')(dense_saliency)\n",
    "\n",
    "    # Inject contrastive loss\n",
    "\n",
    "    return features, features_saliency, gap, gap_saliency, saliency_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2474956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package=\"channel_att\")\n",
    "class channel_attention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    channel attention module\n",
    "\n",
    "    Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ratio=8, **kwargs):\n",
    "        super(channel_attention, self).__init__(**kwargs)\n",
    "        self.ratio = ratio\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(channel_attention, self).get_config()\n",
    "        config.update({'ratio': self.ratio})\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        channel = input_shape[-1]\n",
    "        self.shared_layer_one = tf.keras.layers.Dense(\n",
    "            channel // self.ratio,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            use_bias=True,\n",
    "            bias_initializer='zeros'\n",
    "        )\n",
    "        self.shared_layer_two = tf.keras.layers.Dense(\n",
    "            channel, kernel_initializer='he_normal', use_bias=True, bias_initializer='zeros'\n",
    "        )\n",
    "        super(channel_attention, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def call(self, inputs):\n",
    "        channel = inputs.get_shape().as_list()[-1]\n",
    "\n",
    "        avg_pool = tf.keras.layers.GlobalAveragePooling3D()(inputs)\n",
    "        avg_pool = tf.keras.layers.Reshape((1, 1, 1, channel))(avg_pool)\n",
    "        avg_pool = self.shared_layer_one(avg_pool)\n",
    "        avg_pool = self.shared_layer_two(avg_pool)\n",
    "\n",
    "        max_pool = tf.keras.layers.GlobalMaxPooling3D()(inputs)\n",
    "        max_pool = tf.keras.layers.Reshape((1, 1, 1, channel))(max_pool)\n",
    "        max_pool = self.shared_layer_one(max_pool)\n",
    "        max_pool = self.shared_layer_two(max_pool)\n",
    "\n",
    "        feature = tf.keras.layers.Add()([avg_pool, max_pool])\n",
    "        feature = tf.keras.layers.Activation('sigmoid')(feature)\n",
    "\n",
    "        return tf.keras.layers.multiply([inputs, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a28ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package=\"spatial_att\")\n",
    "class spatial_attention(tf.keras.layers.Layer):\n",
    "    \"\"\" spatial attention module\n",
    "\n",
    "    Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size=7, **kwargs):\n",
    "        super(spatial_attention, self).__init__(**kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(spatial_attention, self).get_config()\n",
    "        config.update({'kernel_size': self.kernel_size})\n",
    "        return config\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv3d = tf.keras.layers.Conv3D(\n",
    "            filters=1,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            activation='sigmoid',\n",
    "            kernel_initializer='he_normal',\n",
    "            use_bias=False\n",
    "        )\n",
    "        super(spatial_attention, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def call(self, inputs):\n",
    "        avg_pool = tf.keras.layers.Lambda(\n",
    "            lambda x: tf.keras.backend.mean(x, axis=-1, keepdims=True)\n",
    "        )(inputs)\n",
    "        max_pool = tf.keras.layers.Lambda(\n",
    "            lambda x: tf.keras.backend.max(x, axis=-1, keepdims=True)\n",
    "        )(inputs)\n",
    "        concat = tf.keras.layers.Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "        feature = self.conv3d(concat)\n",
    "\n",
    "        return tf.keras.layers.multiply([inputs, feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package=\"cbam_block\", name=\"cbam\")\n",
    "def cbam_block(feature, ratio=8, kernel_size=7):\n",
    "    \"\"\"\n",
    "    Contains the implementation of Convolutional Block Attention Module(CBAM) block.\n",
    "    As described in https://arxiv.org/abs/1807.06521.\n",
    "    \"\"\"\n",
    "\n",
    "    feature = channel_attention(ratio=ratio)(feature)\n",
    "    feature = spatial_attention(kernel_size=kernel_size)(feature)\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d14b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PsiNet with CBAM\n",
    "def psi_net(input_tensor, additional_inputs, ratio=8, kernel_size=7):\n",
    "    \"\"\"Enhanced PsiNet Block with CBAM Attention and Dynamic Coefficients\"\"\"\n",
    "    # Convolutional layers with residual connection\n",
    "    x = layers.TimeDistributed(layers.Conv2D(32, (3, 3), padding='same'))(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Residual connection\n",
    "    shortcut = (\n",
    "        layers.TimeDistributed(layers.Conv2D(32, (1, 1), padding='same'))(input_tensor)\n",
    "        if x.shape[-1] != input_tensor.shape[-1] else input_tensor\n",
    "    )\n",
    "    x = layers.Add()([x, shortcut])\n",
    "\n",
    "    # CBAM attention\n",
    "    x = cbam_block(x, ratio=ratio, kernel_size=kernel_size)\n",
    "\n",
    "    # Dynamic weighting for fusion\n",
    "    num_additional_inputs = len(additional_inputs)\n",
    "    coeffs = layers.Dense(num_additional_inputs + 1, activation='softmax', kernel_initializer='he_uniform')(\n",
    "        layers.GlobalAveragePooling3D()(x)\n",
    "    )\n",
    "\n",
    "    # Reshape coeffs for broadcasting\n",
    "    coeffs = layers.Lambda(\n",
    "        lambda c: tf.expand_dims(tf.expand_dims(tf.expand_dims(c, 1), 1), 1),\n",
    "        output_shape=(None, 1, 1, 1, num_additional_inputs + 1),\n",
    "    )(coeffs)\n",
    "    # coeffs shape: [batch_size, 1, 1, 1, num_additional_inputs + 1]\n",
    "\n",
    "    # Use Lambda to dynamically broadcast `coeffs` to match `x`\n",
    "    coeffs = layers.Lambda(\n",
    "        lambda args: tf.broadcast_to(\n",
    "            args[0],\n",
    "            [tf.shape(args[1])[0], tf.shape(args[1])[1], tf.shape(args[1])[2], tf.shape(args[1])[3], tf.shape(args[0])[-1]],\n",
    "        ),\n",
    "        output_shape=(None, None, None, None, num_additional_inputs + 1),\n",
    "    )([coeffs, x])\n",
    "\n",
    "    # Fuse inputs dynamically\n",
    "    fused = layers.Lambda(\n",
    "        lambda args: args[0] * args[1],\n",
    "        output_shape=x.shape[1:],  # Shape of `x` remains unchanged\n",
    "    )([coeffs[..., 0:1], x])  # coeffs[..., 0:1] matches x's shape\n",
    "\n",
    "    for i, add_input in enumerate(additional_inputs):\n",
    "        # Align channel dimensions of additional inputs\n",
    "        reduced_input = layers.TimeDistributed(layers.Conv2D(32, (1, 1), padding='same'))(add_input)\n",
    "        # fused = layers.Lambda(\n",
    "        #     lambda args: args[0] + args[1] * args[2],\n",
    "        #     output_shape=fused.shape[1:],  # Shape of `fused` remains unchanged\n",
    "        # )([fused, coeffs[..., i + 1:i + 2], reduced_input])\n",
    "        # Weighted additional input\n",
    "        weighted_input = layers.Lambda(\n",
    "            lambda args: args[0] * args[1],\n",
    "            output_shape=reduced_input.shape[1:],  # (Time, H, W, C)\n",
    "        )([coeffs[..., i + 1:i + 2], reduced_input])\n",
    "\n",
    "    # Concatenate along the channel axis (-1)\n",
    "    fused = layers.Concatenate(axis=-1)([fused, weighted_input])\n",
    "\n",
    "    fused = tf.keras.layers.BatchNormalization()(fused)\n",
    "\n",
    "    return fused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7113238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seviko/skripsi/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'spatial_attention_module', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "video_input = tf.keras.Input(shape=(n_frames, 224, 224, 3))  # (N, 224, 224, 3)\n",
    "\n",
    "features, features_saliency, gap, gap_saliency, _ = build_dfnet_model(video_input, base_filters=32)\n",
    "\n",
    "# Fusion\n",
    "fusion = psi_net(features, [features_saliency])  # (B, N, 2F)\n",
    "drop = layers.Dropout(0.3)(fusion)\n",
    "dense = layers.Dense(32, activation='relu')(drop)\n",
    "gap_fusion = layers.GlobalAveragePooling3D()(dense)\n",
    "output = layers.Dense(1, name='fusion')(gap_fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDiversityLossLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, lambda_div=0.01, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.lambda_div = lambda_div\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gap1, gap2 = inputs\n",
    "        # loss = -tf.reduce_mean(tf.square(gap1 - gap2))  # encourage dissimilarity\n",
    "        loss = tf.keras.losses.cosine_similarity(gap1,gap2) + 1\n",
    "        self.add_loss(self.lambda_div * loss)\n",
    "        return gap1  # or gap2, or just pass it through if needed\n",
    "        \n",
    "# gap = ContrastiveDiversityLossLayer(lambda_div=0.01, name = 'out_ori')([gap, gap_saliency])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e01a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import BinaryFocalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Hyperparameter for contrastive weight\n",
    "lambda_div = 0.01\n",
    "\n",
    "# Define focal loss\n",
    "focal_loss_fn = BinaryFocalCrossentropy(from_logits=True)\n",
    "\n",
    "# Define model\n",
    "model = tf.keras.Model(inputs=video_input, outputs=[output, gap, gap_saliency])\n",
    "\n",
    "# Use focal loss for the fusion output only\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1 = 0.9, weight_decay = 0.0005),\n",
    "    loss={\n",
    "        \"fusion\": focal_loss_fn,\n",
    "        \"out\": focal_loss_fn,\n",
    "        \"out_sal\": focal_loss_fn\n",
    "        },  # you can ignore gap/gap_saliency for direct supervision\n",
    "    metrics={\"fusion\": AUC(from_logits=True, name=\"auc\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece3f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_4  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">589,856</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_5  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,568</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ channel_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">channel_attention</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_attention   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ channel_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">spatial_attention</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_attentio… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │            │ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │            │ spatial_attentio… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_3  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│                     │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)           │ <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, │            │                   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_6  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">40,992</span> │ time_distributed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ spatial_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ get_item_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ lambda_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_saliency      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,281</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_sal             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_saliency[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │ \u001b[38;5;34m23,587,712\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_4  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │    \u001b[38;5;34m589,856\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_5  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │     \u001b[38;5;34m65,568\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ channel_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mchannel_attention\u001b[0m) │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_attention   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ channel_attentio… │\n",
       "│ (\u001b[38;5;33mspatial_attention\u001b[0m) │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ spatial_attentio… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│                     │ \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m66\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_2 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply (\u001b[38;5;33mMultiply\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m224\u001b[0m,   │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │            │ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_3 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ lambda_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, │            │ spatial_attentio… │\n",
       "│                     │ \u001b[38;5;34m2\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_3  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │  \u001b[38;5;34m4,049,571\u001b[0m │ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│                     │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, │            │                   │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_item_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ lambda_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGetItem\u001b[0m)           │ \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, │            │                   │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ time_distributed_6  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │     \u001b[38;5;34m40,992\u001b[0m │ time_distributed… │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ get_item[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ spatial_attentio… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_5 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ get_item_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ time_distributed… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │ \u001b[38;5;34m64\u001b[0m)               │            │ lambda_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │      \u001b[38;5;34m2,080\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│                     │ \u001b[38;5;34m2048\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ time_distributed… │\n",
       "│                     │ \u001b[38;5;34m1280\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │      \u001b[38;5;34m2,049\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│                     │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_saliency      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,  │      \u001b[38;5;34m1,281\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ fusion (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ out_sal             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ dense_saliency[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,339,592</span> (108.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,339,592\u001b[0m (108.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,244,257</span> (107.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,244,257\u001b[0m (107.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">95,335</span> (372.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m95,335\u001b[0m (372.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754025846.642655    1453 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "dummy_input = tf.zeros((1, n_frames, 224, 224, 3))  # Adjust shape as needed\n",
    "_ = model(dummy_input)  # This will build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b72df",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"dfnet_best_model_contrastive_protocol_3_f.weights.h5\",\n",
    "    monitor=\"val_fusion_auc\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "earlystop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_fusion_auc\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "\n",
    "lr_reduce_cb = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_fusion_auc\",\n",
    "    factor=0.8,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd4ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1754026079.795593    3539 service.cc:152] XLA service 0x7f8570002950 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1754026079.795637    3539 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050, Compute Capability 8.6\n",
      "2025-08-01 12:28:11.216845: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-08-01 12:36:06.225626: E external/local_xla/xla/service/slow_operation_alarm.cc:73] \n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_409549__.429637] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "2025-08-01 12:36:46.634937: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'input_maximum_reduce_fusion_2', 260 bytes spill stores, 248 bytes spill loads\n",
      "\n",
      "2025-08-01 12:36:51.181231: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 2m44.955670592s\n",
      "\n",
      "********************************\n",
      "[Compiling module a_inference_one_step_on_data_409549__.429637] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n",
      "I0000 00:00:1754026611.230268    3539 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 84/125\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m52s\u001b[0m 1s/step - fusion_auc: 0.5752 - fusion_loss: 0.2772 - loss: 0.6362 - out_loss: 0.2133 - out_sal_loss: 0.1456"
     ]
    }
   ],
   "source": [
    "# model.load_weights(\"dfnet_best_model_contrastive_epoch_60.weights.h5\")\n",
    "# model.load_weights(\"dfnet_best_model_contrastive protocol_1_no_crop_fusion_3.weights.h5\")\n",
    "history = model.fit(\n",
    "    train_ds_oulu,\n",
    "    #validation_data=test_ds_oulu,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=125,\n",
    "    #callbacks=[checkpoint_cb],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"dfnet_best_model_contrastive protocol_1_no_crop_fusion_3.weights.h5\")\n",
    "# model.load_weights(\"dfnet_best_model_contrastive_protocol_3_f.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff78aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "y_pred_keras,_,_ = model.predict(test_ds_oulu)\n",
    "y_pred_keras = y_pred_keras.ravel()\n",
    "\n",
    "y_test = []\n",
    "for idx in range(len(y_pred_keras)):\n",
    "    if test_annotation[0][idx][0] == '+': # 0 as genuine\n",
    "        y_test.extend([0])\n",
    "    else:\n",
    "        y_test.extend([1])  # 1 as fake\n",
    "\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fda787",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = list()\n",
    "fnr = list()\n",
    "\n",
    "thresholds = np.linspace(y_pred_keras.min(), y_pred_keras.max(), 1000)\n",
    "for thr in thresholds:\n",
    "    pred = y_pred_keras >= thr\n",
    "    TN = np.sum((y_test == 0) & (pred == False))  # Genuine detected as Genuine: True Negative   -- True Accept\n",
    "    FN = np.sum((y_test == 1) & (pred == False))  # Fake detected as genuine: False Negative  -- False Accept\n",
    "    FP = np.sum((y_test == 0) & (pred == True))   # Genuine detected as fake: False Positive  -- False Reject\n",
    "    TP = np.sum((y_test == 1) & (pred == True))   # Fake detected as Fake: True Positive   -- True Reject\n",
    "    x = 0 if FP == 0 else FP/(FP+TN)\n",
    "    y = 0 if FN == 0 else FN/(FN+TP)\n",
    "    fpr.extend([x])\n",
    "    fnr.extend([y])\n",
    "\n",
    "fpr = np.array(fpr)\n",
    "fnr = np.array(fnr)\n",
    "\n",
    "auc = auc(fpr, 1-fnr)\n",
    "bpcer = fpr[np.argmin(abs(fpr+fnr))]\n",
    "apcer = fnr[np.argmin(abs(fpr+fnr))]\n",
    "acer = (apcer+bpcer)/2\n",
    "\n",
    "print(apcer)\n",
    "print(bpcer)\n",
    "print(acer)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5486a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.arange(len(fnr)) # index for df\n",
    "roc = pd.DataFrame({'fpr' : pd.Series(fpr, index=i),'fnr' : pd.Series(fnr, index = i), '1-fpr' : pd.Series(1-fpr, index = i), 'tf' : pd.Series(fnr + fpr, index = i), 'thresholds' : pd.Series(thresholds, index = i)})\n",
    "roc.iloc[(roc.tf).argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca637f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Mask\n",
    "_, _, _, _, mask = build_dfnet_model(video_input)  # define model\n",
    "model_saliency = tf.keras.Model(inputs=video_input, outputs=mask)\n",
    "\n",
    "# Prepare sample input\n",
    "sample_video = next(iter(train_ds_oulu))[0]  # shape (B, N, 224, 224, 3)\n",
    "masks_val = model_saliency.predict(sample_video)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert to numpy if needed\n",
    "if isinstance(masks_val, tf.Tensor):\n",
    "    masks_val = masks_val.numpy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(masks_val[0, 0, :, :, :])\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Inverted Saliency Mask\")\n",
    "plt.savefig(\"mask_sample.png\", bbox_inches='tight')  # saves to disk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
